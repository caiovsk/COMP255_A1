{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "def visualisation():\n",
    "    for i in range(19):\n",
    "        df = pd.read_csv('daliac/dataset_' + str(i+1) + '.txt', sep=',', header=None)\n",
    "    for i in range(1, 14):\n",
    "        df_exercise = df[df[24] == i].values\n",
    "        plt.plot(df_exercise[500:1500, :])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove noise\n",
    "def removeNoise():\n",
    "    for i in range(19):\n",
    "        df = pd.read_csv('daliac/dataset_' + str(i+1) + '.txt', sep=',', header=None)\n",
    "    for i in range(1,14):\n",
    "        df_exercise = df[df[24] == i].values\n",
    "        b, a = signal.butter(4, 0.04, 'lowpass', analog=False)\n",
    "        for k in range(24):\n",
    "            df_exercise[:,k] = signal.lfilter(b, a, df_exercise[:, k])\n",
    "        plt.plot(df_exercise[500:1500, :])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEngineering():    \n",
    "    for i in range(19):\n",
    "        df = pd.read_csv('daliac/dataset_' + str(i + 1) + '.txt', sep=',', header=None)\n",
    "        print('deal with dataset ' + str(i + 1))\n",
    "        for c in range(1, 14):\n",
    "            activity_data = df[df[24] == c].values\n",
    "            b, a = signal.butter(4, 0.04, 'low', analog=False)\n",
    "            for j in range(24):\n",
    "                activity_data[:, j] = signal.lfilter(b, a, activity_data[:, j])\n",
    "\n",
    "                training = np.empty(shape=(0, 10))\n",
    "                testing = np.empty(shape=(0, 10))\n",
    "            \n",
    "\n",
    "                datat_len = len(activity_data)\n",
    "                training_len = math.floor(datat_len * 0.8)\n",
    "                training_data = activity_data[:training_len, :]\n",
    "                testing_data = activity_data[training_len:, :]\n",
    "                training_sample_number = training_len // 1000 + 1\n",
    "                testing_sample_number = (datat_len - training_len) // 1000 + 1\n",
    "\n",
    "                for s in range(1):\n",
    "                    if s < training_sample_number - 1 and s < testing_sample_number - 1:\n",
    "                        sample_data = training_data[1000*s:1000*(s + 1), :]\n",
    "                        sample_data = testing_data[1000*s:1000*(s + 1), :]\n",
    "                    else:\n",
    "                        sample_data = training_data[1000*s:, :]\n",
    "                        sample_data = testing_data[1000*s:, :]\n",
    "\n",
    "                    feature_sample = []\n",
    "                    for i in range(3):\n",
    "                        feature_sample.append(np.min(sample_data[:, i]))\n",
    "                        feature_sample.append(np.max(sample_data[:, i]))\n",
    "                        feature_sample.append(np.mean(sample_data[:, i]))\n",
    "                    feature_sample.append(sample_data[0, -1])\n",
    "                    feature_sample = np.array([feature_sample])\n",
    "                    training = np.concatenate((training, feature_sample), axis=0)\n",
    "                    testing = np.concatenate((testing, feature_sample), axis=0)\n",
    "\n",
    "                    df_training = pd.DataFrame(training)\n",
    "                    df_testing = pd.DataFrame(testing)\n",
    "                    df_training.to_csv('training_data.csv', index=None, header=None)\n",
    "                    df_testing.to_csv('testing_data.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_and_evaluation_example():\n",
    "    df_training = pd.read_csv('training_data.csv', header=None)\n",
    "    df_testing = pd.read_csv('testing_data.csv', header=None)\n",
    "\n",
    "    y_train = df_training[9].values\n",
    "    y_train = y_train - 1\n",
    "    df_training = df_training.drop([9], axis=1)\n",
    "    X_train = df_training.values\n",
    "    y_test = df_testing[9].values\n",
    "    y_test = y_test - 1\n",
    "    df_testing = df_testing.drop([9], axis=1)\n",
    "    X_test = df_testing.values\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred)) \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1e-3, 1e-2, 1e-1, 1, 10, 100]}]\n",
    "    acc_scorer = make_scorer(accuracy_score)\n",
    "    grid_obj  = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring=acc_scorer)\n",
    "    grid_obj  = grid_obj .fit(X_train, y_train)\n",
    "    clf = grid_obj.best_estimator_\n",
    "    print('best clf:', clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal with dataset 1\n",
      "deal with dataset 2\n",
      "deal with dataset 3\n",
      "deal with dataset 4\n",
      "deal with dataset 5\n",
      "deal with dataset 6\n",
      "deal with dataset 7\n",
      "deal with dataset 8\n",
      "deal with dataset 9\n",
      "deal with dataset 10\n",
      "deal with dataset 11\n",
      "deal with dataset 12\n",
      "deal with dataset 13\n",
      "deal with dataset 14\n",
      "deal with dataset 15\n",
      "deal with dataset 16\n",
      "deal with dataset 17\n",
      "deal with dataset 18\n",
      "deal with dataset 19\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-357ea8cb425f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     removeNoise()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfeatureEngineering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel_training_and_evaluation_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-ba4331f8a691>\u001b[0m in \u001b[0;36mmodel_training_and_evaluation_example\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             )\n\u001b[1;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 3"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     visualisation()\n",
    "#     removeNoise()\n",
    "    featureEngineering()\n",
    "    model_training_and_evaluation_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
